{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "mBall_yahoo4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kazuki0505/zaico-fixcan_heroku/blob/master/mBall_yahoo4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "swvOrEQMs8Oh",
        "colab_type": "text"
      },
      "source": [
        "# a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "54S9iq9Os8Ok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83f1d7c-5a21-4a11-95c5-76368ac59e80"
      },
      "source": [
        "a\n",
        "ここにmBall_yahoo4全部入れて、一つずつセル分けて。試せばいい。Breakで一周のみにするのを忘れずに\n",
        "sql_pandasと横並べで比較するのもよし\n",
        "コメントアウトされた箇所はコピペしないから、排除するショートカット＞\n",
        "Pycharmでコメントアウト削除、なければJuoyterで削除\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-76-8f5cf245caf7>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    ここにmBall_yahoo4全部入れて、一つずつセル分けて。試せばいい。Breakで一周のみにするのを忘れずに\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf_AHZXhzQht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO0C3C3IzbqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2359cd2-18c1-42fc-855a-e04feda6c2cb"
      },
      "source": [
        "!pip freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aiohttp==3.6.2\n",
            "anaconda-client==1.7.2\n",
            "anaconda-navigator==1.9.12\n",
            "astroid @ file:///D:/bld/astroid_1591645286655/work\n",
            "async-timeout==3.0.1\n",
            "attrs==19.3.0\n",
            "autopep8==1.5.2\n",
            "backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n",
            "beautifulsoup4 @ file:///D:/bld/beautifulsoup4_1589761082943/work\n",
            "bleach @ file:///home/conda/feedstock_root/build_artifacts/bleach_1588608214987/work\n",
            "bokeh @ file:///D:/bld/bokeh_1592869751982/work\n",
            "brotlipy==0.7.0\n",
            "certifi==2020.6.20\n",
            "cffi==1.14.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle @ file:///home/conda/feedstock_root/build_artifacts/cloudpickle_1593623337153/work\n",
            "clyent==1.2.2\n",
            "colorama==0.4.3\n",
            "conda==4.8.3\n",
            "conda-build==3.19.2\n",
            "conda-package-handling==1.6.0\n",
            "conda-verify==3.1.1\n",
            "cryptography==2.9.2\n",
            "cytoolz==0.10.1\n",
            "dask @ file:///home/conda/feedstock_root/build_artifacts/dask-core_1595035454217/work\n",
            "dask-labextension @ file:///home/conda/feedstock_root/build_artifacts/dask-labextension_1588177406011/work\n",
            "decorator==4.4.2\n",
            "defusedxml==0.6.0\n",
            "distributed @ file:///D:/bld/distributed_1595036696609/work\n",
            "entrypoints==0.3\n",
            "et-xmlfile==1.0.1\n",
            "filelock @ file:///home/conda/feedstock_root/build_artifacts/filelock_1589994591731/work\n",
            "flake8==3.7.9\n",
            "future==0.18.2\n",
            "gitdb @ file:///home/conda/feedstock_root/build_artifacts/gitdb_1588651542737/work\n",
            "GitPython @ file:///home/conda/feedstock_root/build_artifacts/gitpython_1590897464411/work\n",
            "glob2==0.7\n",
            "googletrans==2.4.0\n",
            "HeapDict==1.0.1\n",
            "idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1593328102638/work\n",
            "importlib-metadata @ file:///D:/bld/importlib-metadata_1593211612489/work\n",
            "ipykernel @ file:///D:/bld/ipykernel_1595101491454/work/dist/ipykernel-5.3.3-py3-none-any.whl\n",
            "ipysheet==0.4.3\n",
            "ipython @ file:///D:/bld/ipython_1593235680304/work\n",
            "ipython-genutils==0.2.0\n",
            "ipywidgets==7.5.1\n",
            "isort @ file:///D:/bld/isort_1595132270135/work\n",
            "jdcal==1.4.1\n",
            "jedi==0.15.2\n",
            "Jinja2==2.11.2\n",
            "json5 @ file:///home/conda/feedstock_root/build_artifacts/json5_1591810480056/work\n",
            "jsonschema==3.2.0\n",
            "jupyter-client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1594732094290/work\n",
            "jupyter-core==4.6.3\n",
            "jupyter-http-over-ws==0.0.8\n",
            "jupyter-lsp==0.8.0\n",
            "jupyter-server-proxy @ file:///home/conda/feedstock_root/build_artifacts/jupyter-server-proxy_1590048206892/work\n",
            "jupyterlab==1.2.16\n",
            "jupyterlab-code-formatter==0.2.3\n",
            "jupyterlab-git==0.20.0\n",
            "jupyterlab-github==2.0.0\n",
            "jupyterlab-server @ file:///home/conda/feedstock_root/build_artifacts/jupyterlab_server_1593951277307/work\n",
            "lazy-object-proxy==1.4.3\n",
            "libarchive-c==2.9\n",
            "lxml @ file:///D:/bld/lxml_1589927701860/work\n",
            "MarkupSafe==1.1.1\n",
            "mccabe==0.6.1\n",
            "menuinst==1.4.16\n",
            "mistune==0.8.4\n",
            "msgpack==1.0.0\n",
            "multidict @ file:///D:/bld/multidict_1588134902151/work\n",
            "navigator-updater==0.2.1\n",
            "nbconvert==5.6.1\n",
            "nbdime @ file:///home/conda/feedstock_root/build_artifacts/nbdime_1588773248389/work\n",
            "nbformat @ file:///home/conda/feedstock_root/build_artifacts/nbformat_1594060262917/work\n",
            "notebook @ file:///D:/bld/notebook_1594079038368/work\n",
            "numpy @ file:///D:/bld/numpy_1594931896947/work\n",
            "olefile==0.46\n",
            "openpyxl==3.0.3\n",
            "packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1589925210001/work\n",
            "pandas @ file:///D:/bld/pandas_1592422178599/work\n",
            "pandocfilters==1.4.2\n",
            "parso==0.7.0\n",
            "pickleshare==0.7.5\n",
            "Pillow @ file:///D:/bld/pillow_1594213048891/work\n",
            "pkginfo==1.5.0.1\n",
            "pluggy @ file:///D:/bld/pluggy_1592827687923/work\n",
            "prometheus-client @ file:///home/conda/feedstock_root/build_artifacts/prometheus_client_1590412252446/work\n",
            "prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1592500439797/work\n",
            "pscript @ file:///home/conda/feedstock_root/build_artifacts/pscript_1589197636232/work\n",
            "psutil @ file:///D:/bld/psutil_1594827123623/work\n",
            "psycopg2==2.8.5\n",
            "ptyprocess==0.6.0\n",
            "pycodestyle==2.5.0\n",
            "pycosat==0.6.3\n",
            "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1593275161868/work\n",
            "pydocstyle==5.0.2\n",
            "pyflakes==2.1.1\n",
            "Pygments==2.6.1\n",
            "pylint==2.3.1\n",
            "pymongo==3.10.1\n",
            "pyOpenSSL==19.1.0\n",
            "pyparsing==2.4.7\n",
            "PyQt5==5.12.3\n",
            "PyQt5-sip==4.19.18\n",
            "PyQtChart==5.12\n",
            "PyQtWebEngine==5.12.1\n",
            "pyrsistent==0.16.0\n",
            "PySocks==1.7.1\n",
            "python-dateutil==2.8.1\n",
            "python-jsonrpc-server @ file:///home/conda/feedstock_root/build_artifacts/python-jsonrpc-server_1588783985962/work\n",
            "python-language-server==0.31.10\n",
            "pytz==2020.1\n",
            "pywin32==227\n",
            "pywinpty==0.5.7\n",
            "PyYAML==5.3.1\n",
            "pyzmq==19.0.1\n",
            "QtPy==1.9.0\n",
            "requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1592425495151/work\n",
            "rope @ file:///home/conda/feedstock_root/build_artifacts/rope_1588950285934/work\n",
            "ruamel-yaml==0.15.80\n",
            "selenium==3.141.0\n",
            "Send2Trash==1.5.0\n",
            "simpervisor==0.3\n",
            "six @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\n",
            "smmap @ file:///home/conda/feedstock_root/build_artifacts/smmap_1588651577140/work\n",
            "snowballstemmer==2.0.0\n",
            "sortedcontainers @ file:///home/conda/feedstock_root/build_artifacts/sortedcontainers_1591999956871/work\n",
            "soupsieve @ file:///D:/bld/soupsieve_1589778668225/work\n",
            "SQLAlchemy==1.3.18\n",
            "SwatchBooker==0.7.3\n",
            "tblib==1.6.0\n",
            "terminado==0.8.3\n",
            "testpath==0.4.4\n",
            "toolz==0.10.0\n",
            "tornado==6.0.4\n",
            "tqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1594937875116/work\n",
            "traitlets==4.3.3\n",
            "typed-ast==1.4.1\n",
            "typing-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1588470653596/work\n",
            "ujson==1.35\n",
            "urllib3==1.25.9\n",
            "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1592931742287/work\n",
            "webencodings==0.5.1\n",
            "widgetsnbextension @ file:///D:/bld/widgetsnbextension_1594164533747/work\n",
            "win-inet-pton==1.1.0\n",
            "wincertstore==0.2\n",
            "wrapt==1.11.2\n",
            "xlrd==1.2.0\n",
            "xmltodict==0.12.0\n",
            "yapf==0.29.0\n",
            "yarl==1.3.0\n",
            "zict==2.0.0\n",
            "zipp==3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmutSFU_zbxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd10e87-e115-4b46-ed95-d29b53b49b4f"
      },
      "source": [
        "!pip install psycopg2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psycopg2 in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (2.8.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30bkQYYnzPfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50664b3-688d-463b-a502-7c6abdff6742"
      },
      "source": [
        "pip install googletrans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (2.4.0)\n",
            "Requirement already satisfied: requests in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (from googletrans) (2.24.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (from requests->googletrans) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (from requests->googletrans) (1.25.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (from requests->googletrans) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kazuki_juno\\anaconda3\\lib\\site-packages (from requests->googletrans) (2020.6.20)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzZnMulRs8Pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4 は、SQL バージョン\n",
        "##\n",
        "\n",
        "# While i <151: つまり商品数１５１まで＝５０件/ページの３ページまでスクレイプする　\n",
        "# mongoDB 無視\n",
        "# これは、mBallの機能を担うコード。mBall_atk.pyも吸収してみた\n",
        "# 　# mBall_yahooもmBall_atkも、画像１枚目を取得するかしないかの違いで、ほかは全く同じだから\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from openpyxl import load_workbook\n",
        "import time\n",
        "import re\n",
        "\n",
        "import requests, bs4\n",
        "# import lxml.html\n",
        "# from pymongo import MongoClient\n",
        "# import xlwings as xw\n",
        "# import math\n",
        "# from selenium import webdriver\n",
        "# from selenium.common.exceptions import NoSuchElementException\n",
        "# from xlwings.constants import AutoFillType\n",
        "# import shutil\n",
        "from datetime import datetime\n",
        "from uuid import uuid4\n",
        "from googletrans import Translator\n",
        "import json\n",
        "# import pandas as pd\n",
        "# import pythoncom\n",
        "# from pythoncom import com_error\n",
        "# import win32com.client\n",
        "# import win32com\n",
        "# import sys\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "xPk-XdgVs8P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def main():\n",
        "    # check_if_Excel_runs()\n",
        "    # wb = r'C:\\Users\\Kazuki Yuno\\Desktop\\00.myself\\04.Buyer\\0.リサーチ\\keyword\\key_generator.xlsx'\n",
        "\n",
        "# データベースの接続情報\n",
        "connection_config = {\n",
        "    'user': 'postgres',\n",
        "    'password': 'larc1225',\n",
        "    'host': 'localhost',\n",
        "    'port': '5432',  # なくてもOK\n",
        "    'database': 'scraping'\n",
        "}\n",
        "global engine\n",
        "engine = create_engine(\n",
        "    'postgresql://postgres:larc1225@localhost:5432/scraping'.format(**connection_config))\n",
        "\n",
        "    # 検索キーは、後の間を＋にする必要があるが、これエクセルの時点でやるか、ここでやるか> planner では空白で複合キーを生成するので、変更はここで"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "7baJalO_s8QJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f75f53d-b145-4ce5-c19b-f2fabee583fe"
      },
      "source": [
        "market_df = pd.read_sql('market', con=engine, # SELECT文ではなく、テーブル名のみ\n",
        "    columns=['categ num', 'main key', 'キーフレーズ'])\\\n",
        "    .dropna(subset=['キーフレーズ']) # キーフレーズ列のNan を消して表示\n",
        "\n",
        "categ_num_list = market_df.iloc[:, 0]#'categ num']\n",
        "mainKey_list = market_df.iloc[:, 1]#'main key'\n",
        "keyPhrase_list = market_df.iloc[:, 2] #['X-MEN 同人誌', 'batman 同人誌'] #.get_group('X-MEN 同人誌', 'batman 同人誌') # 検索キーを減らしたいなら、ここで\n",
        "                                # iloc、第一引数が行\n",
        "# app = xw.App(visible=True)  # False)\n",
        "# wb2 = app.books.open(atk)\n",
        "# sht2 = wb2.sheets[0]\n",
        "\n",
        "market_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     categ num            main key            キーフレーズ\n",
              "1      73466.0      incense burner                香炉\n",
              "2      73466.0        tea ceremony                茶道\n",
              "4      73466.0     buddhist copper               仏 銅\n",
              "5      73466.0      buddhist altar              仏 飾台\n",
              "6      73466.0        buddhist art            仏像 アート\n",
              "8      73466.0    kanzashi hairpin             かんざし \n",
              "11     73466.0        lacquer ware            漆塗り 骨董\n",
              "20     73466.0                bell           鐘 鈴 骨董品\n",
              "22     73466.0           sculpture             彫刻 香炉\n",
              "23     73466.0           sculpture              彫刻 銅\n",
              "24     73466.0           sculpture              彫刻 木\n",
              "25     73466.0           sculpture              彫刻 龍\n",
              "26     73466.0           sculpture             彫刻 獅子\n",
              "28     38125.0     painting scroll            掛け軸 風景\n",
              "29     38125.0     painting scroll             掛け軸 絹\n",
              "30     38125.0     painting scroll             掛け軸 石\n",
              "31     38125.0     painting scroll            掛け軸 山水\n",
              "34     38126.0              prints             絵 浮世絵\n",
              "35     38126.0              prints             絵 木版画\n",
              "37     38126.0              prints             絵 歌舞伎\n",
              "38     38126.0              prints           絵 喜多川歌麿\n",
              "39     38126.0              prints            絵 葛飾北斎\n",
              "40     38126.0              prints            絵 歌川広重\n",
              "42     38126.0              prints              絵 春画\n",
              "43     37935.0               bowls            茶碗 ガラス\n",
              "44     37935.0               bowls             茶碗 緑茶\n",
              "45     37935.0               bowls           茶碗 パターン\n",
              "46     37935.0               bowls        茶碗 サイン入り 箱\n",
              "47     37935.0               bowls            茶碗 瀬戸焼\n",
              "48     37935.0               bowls            茶碗 清水焼\n",
              "52     37935.0               bowls           茶碗 伊万里焼\n",
              "53     37935.0               bowls            茶碗 九谷焼\n",
              "54     37935.0               bowls           茶碗 伊万里焼\n",
              "69     66841.0              katana                 鞘\n",
              "70     66841.0              katana                 鍔\n",
              "71     66841.0              katana                目貫\n",
              "112     1345.0  shingeki no kyojin    進撃の巨人 フィギュア 限定\n",
              "119    13666.0         dragon ball  ドラゴンボール フィギュア 限定\n",
              "122   158671.0              batman        batman 同人誌\n",
              "123   158671.0              batman       コトブキヤ バットマン\n",
              "125   158671.0           spiderman     コトブキヤ スパイダーマン\n",
              "127    17085.0               x-men         X-MEN 同人誌\n",
              "128   158671.0               x-men       コトブキヤ x-men\n",
              "130   158671.0            avengers     コトブキヤ アベンジャーズ\n",
              "131    75708.0           star wars     コトブキヤ スターウォーズ"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categ num</th>\n",
              "      <th>main key</th>\n",
              "      <th>キーフレーズ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>incense burner</td>\n",
              "      <td>香炉</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>tea ceremony</td>\n",
              "      <td>茶道</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>buddhist copper</td>\n",
              "      <td>仏 銅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>buddhist altar</td>\n",
              "      <td>仏 飾台</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>buddhist art</td>\n",
              "      <td>仏像 アート</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>kanzashi hairpin</td>\n",
              "      <td>かんざし</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>lacquer ware</td>\n",
              "      <td>漆塗り 骨董</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>bell</td>\n",
              "      <td>鐘 鈴 骨董品</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>sculpture</td>\n",
              "      <td>彫刻 香炉</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>sculpture</td>\n",
              "      <td>彫刻 銅</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>sculpture</td>\n",
              "      <td>彫刻 木</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>sculpture</td>\n",
              "      <td>彫刻 龍</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>73466.0</td>\n",
              "      <td>sculpture</td>\n",
              "      <td>彫刻 獅子</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>38125.0</td>\n",
              "      <td>painting scroll</td>\n",
              "      <td>掛け軸 風景</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>38125.0</td>\n",
              "      <td>painting scroll</td>\n",
              "      <td>掛け軸 絹</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>38125.0</td>\n",
              "      <td>painting scroll</td>\n",
              "      <td>掛け軸 石</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>38125.0</td>\n",
              "      <td>painting scroll</td>\n",
              "      <td>掛け軸 山水</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 浮世絵</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 木版画</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 歌舞伎</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 喜多川歌麿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 葛飾北斎</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 歌川広重</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>38126.0</td>\n",
              "      <td>prints</td>\n",
              "      <td>絵 春画</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 ガラス</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 緑茶</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 パターン</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 サイン入り 箱</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 瀬戸焼</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 清水焼</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 伊万里焼</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 九谷焼</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>37935.0</td>\n",
              "      <td>bowls</td>\n",
              "      <td>茶碗 伊万里焼</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>66841.0</td>\n",
              "      <td>katana</td>\n",
              "      <td>鞘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>66841.0</td>\n",
              "      <td>katana</td>\n",
              "      <td>鍔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>66841.0</td>\n",
              "      <td>katana</td>\n",
              "      <td>目貫</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>1345.0</td>\n",
              "      <td>shingeki no kyojin</td>\n",
              "      <td>進撃の巨人 フィギュア 限定</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>13666.0</td>\n",
              "      <td>dragon ball</td>\n",
              "      <td>ドラゴンボール フィギュア 限定</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>158671.0</td>\n",
              "      <td>batman</td>\n",
              "      <td>batman 同人誌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>158671.0</td>\n",
              "      <td>batman</td>\n",
              "      <td>コトブキヤ バットマン</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>158671.0</td>\n",
              "      <td>spiderman</td>\n",
              "      <td>コトブキヤ スパイダーマン</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>17085.0</td>\n",
              "      <td>x-men</td>\n",
              "      <td>X-MEN 同人誌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>158671.0</td>\n",
              "      <td>x-men</td>\n",
              "      <td>コトブキヤ x-men</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>158671.0</td>\n",
              "      <td>avengers</td>\n",
              "      <td>コトブキヤ アベンジャーズ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>75708.0</td>\n",
              "      <td>star wars</td>\n",
              "      <td>コトブキヤ スターウォーズ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "hSP0v8cJs8QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_space_htmlTag(s):\n",
        "    p = re.compile(r\"<[^>]*?>\") # htmlTagを削除\n",
        "    remove = p.sub(\"\", s)\n",
        "    space = re.sub(r'\\s+', ' ', remove).strip()  # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "    return space.replace('[', '').replace(']', '') # [] を置換\n",
        "\n",
        "def remove_space_htmlTag_pr(s):\n",
        "    p = re.compile(r\"<[^>]*?>\") # htmlTagを削除\n",
        "    remove = p.sub(\"\", s)\n",
        "    space = re.sub(r'\\s+', ' ', remove).strip()  # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "    return space.replace('[', '').replace(']', '').replace('円（税 0 円） ', '')\n",
        "\n",
        "\n",
        " # mergeのURL列から、新たにitemID 列を導き出す\n",
        "def extract_key(url): # URLからキー（URLの末尾のISBN）を抜き出す。\n",
        "    m = re.search(r'/([^/]+)$', url) # /([^/]+)$\n",
        "    return m.group(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "jvH2cSaks8Qi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd38d0f-c301-412f-f93a-57d0be50a415"
      },
      "source": [
        "list_df = pd.DataFrame(columns=['タイトル', 'url', 'ID', 'Title', 'main key', 'Category'])\n",
        "list_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [タイトル, url, ID, Title, main key, Category]\n",
              "Index: []"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>タイトル</th>\n",
              "      <th>url</th>\n",
              "      <th>ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>main key</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "5LycjyROs8Qv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9e8246-e9c6-45b4-d383-5507f83c58c0"
      },
      "source": [
        "# arr_title_url_id_ = np.empty([0, 3])\n",
        "\n",
        "  #                                        0~ other japanese antique  14~ painting  18= prints\n",
        "#                                             ドラゴンボール 37  ラストは４５\n",
        "        # これは不便、カテゴリ指定で検索ワードをグループ化しながら、毎日自動リサしてほしい\n",
        "# keyPhraase 番号振っても、途中からのリサにならない\n",
        "# ここ、keyPhraseだけ番号振ったらだめ、mainKryやcategは最初から記録してしまう>> 一括で番を振る\n",
        "# list(zip()) とすることで、一括して順番を指定できる　https://stackoverrun.com/ja/q/7531087\n",
        "for mainKey, categ_num, keyPhrase in list(zip(mainKey_list, categ_num_list, keyPhrase_list))[44:]: #[36:]: # [:2]\n",
        "    print(mainKey, categ_num, keyPhrase)\n",
        "    # url = 'https://auctions.yahoo.co.jp/search/search' # while 内に入れることで解決。ここだと、2ページ目の頭の品のページに行ってしまう\n",
        "    url_list = []\n",
        "    title_list = [] # 空のDFを2列分用意し、append する方法もあるはずだが、次回\n",
        "    itemid_list = []\n",
        "    # price_list = []\n",
        "    i = 1\n",
        "    while i < 61: # 151 20ずつ or 50ずつ繰り上がる\n",
        "        url = 'https://auctions.yahoo.co.jp/search/search' # 正規表現による置換はやめた\n",
        "        # カテゴリ別に、Param設定を買えられる。If \"ドラゴンボール フィギュア\" : 即決品のみ\n",
        "        params = {'q': keyPhrase, 'va': keyPhrase, 'exflg': '1', 'b': i, 'n': '20', # 50, 100\n",
        "                  'min': '4000', 'max': '51999', 'price_type': 'bidorbuyprice'}\n",
        "        # 注意: 即決のみにするには、min かmaxを指定する必要がある\n",
        "        # # 'istatus': '',\n",
        "        res = requests.get(url, params=params)\n",
        "        print(res.url)\n",
        "        \n",
        "        res.raise_for_status()\n",
        "        soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
        "        #   url_list = []\n",
        "        # scrape_list_page(soup, url_list, title_list)\n",
        "        elems = soup.select(\"a[class='Product__titleLink']\")\n",
        "        for a in elems:  # '#listBook a[itemprop=\"url\"]'):\n",
        "        # print(a)\n",
        "            elem_url = a.get('href')\n",
        "            print(elem_url)\n",
        "            \n",
        "            url_list.append(elem_url)\n",
        "            # time.sleep(1)\n",
        "            # yield url\n",
        "            # title\n",
        "            itemid = extract_key(elem_url)\n",
        "            itemid_list.append(itemid)\n",
        "        # title_list = []\n",
        "        elems = soup.select(\"a[class='Product__titleLink']\")\n",
        "        # elems = soup.select(\"#allContents > div.l-wrapper.cf > div.l-contents > div.l-contentsBody > div > div.Result__body > div.Products.Products--grid > div > ul > li:nth-child(1) > div.Product__detail > h3 > a\")\n",
        "        for elem in elems:\n",
        "        # print(elem)\n",
        "            title = elem.get('title')\n",
        "            # print(elem)\n",
        "            title_list.append(title)\n",
        "            print(title)\n",
        "            \n",
        "        # 価格\n",
        "        # elems = soup.select(\"span[class='Product__priceValue.u-textRed']\")\n",
        "\n",
        "        # print('OK')\n",
        "        i += 20\n",
        "        time.sleep(3)\n",
        "        break\n",
        "    # 重複分はATKに追加しないようにする"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-85-f596397871eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ここ、keyPhraseだけ番号振ったらだめ、mainKryやcategは最初から記録してしまう>> 一括で番を振る\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# list(zip()) とすることで、一括して順番を指定できる　https://stackoverrun.com/ja/q/7531087\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mmainKey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcateg_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyPhrase\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainKey_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcateg_num_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyPhrase_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m44\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#[36:]: # [:2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainKey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcateg_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyPhrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# url = 'https://auctions.yahoo.co.jp/search/search' # while 内に入れることで解決。ここだと、2ページ目の頭の品のページに行ってしまう\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "_Jr0pGRIs8Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # title_list をATｋのタイトル列と比べ、もし重複していれば, title_listから重複分を削除. # ２つの円のベン図の半月 = df - merge(inner)\n",
        "    # title_listとurl_list を接合 （titleだけ重複分を消しても、urlが残っているんじゃズレが生じるから\n",
        "    df1 = pd.DataFrame({'タイトル': title_list, 'url': url_list, 'ID': itemid_list}) #, columns=['SKU']) # 2つのリストを一つのDFに\n",
        "    # pd.DataFrame({'Mean': mean, 'Median': med, 'SD': sd})\n",
        "    # ここにsql_df 入れなくて良い？？ >> ループごとに、追加したてのタイトルも比較対象にしたいから、ここに入れて。違うキーで調べても、同じ品を取るケースに備えて\n",
        "    df1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "VOk0AiMus8RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    sql_df = pd.read_sql('atklist2', con=engine,\n",
        "                         columns=['タイトル'])  # skiprows=2, encoding='cp932') #.columns = ['title']\n",
        "    # for index, row in df.iterrows():\n",
        "    #     if row # row['開始価格'] == row['開始価格2']\n",
        "    #         df.drop(index, inplace=True)\n",
        "    sql_df\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "mXV8o8whs8RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    on = ['タイトル']  # , 'url'] # https://stackoverflow.com/questions/48912242/how-to-drop-duplicates-from-one-data-frame-if-found-in-another-dataframe\n",
        "    merge = df1.merge(sql_df[on], on=on, how='left', indicator=True)\\\n",
        "        .query('_merge == \"left_only\"').drop('_merge', 1) # 左＝df1にのみ存在する（(df2との重複を除く）タイトルにQueryしたあと、merge列を削除\n",
        "#     print(\n",
        "    merge # タイトルと url\n",
        "    \n",
        "    # 既存のATKタイトルと、リサ結果のタイトルの重複は消えるが、結果タイトル(df1)内での重複は消えない\n",
        "    # ループごとにatk を保存し、df2読み込む毎に各ループ更新直後のリストを読み込めばいい"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "tOKMP1HFs8RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merge=merge.reset_index(drop=True)\n",
        "merge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "rk0bVOKKs8Rl",
        "colab_type": "text"
      },
      "source": [
        "#### While try をコメントアウトしてるから後で戻して\n",
        "#### リスト作成時、名前に連番が入ってしまうのを解決して\n",
        "#### 18行にタイトルではない値が追加されてしまう＞iloc[i: i+1] の部分で、例えば17行まで来ると... ilocでインデックス17 =18行目（＝値なし）まで翻訳してリストにappendすることになる。 ＞＞ while len(merge) >= i: の = を外すことで解決。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "2FMGeeTRs8Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # タイトル整形、英訳前に>> HTML削除、不要文字置換\n",
        "    # merge2 = remove_space_htmlTag(merge.iloc[:, 1])\n",
        "\n",
        "    # タイトル翻訳\n",
        "     # タイトル列に絞り、字数制限、余分の絵文字などを排除\n",
        "    def left(text, n):\n",
        "        return text[:n]\n",
        "    merge_title = left(merge['タイトル'], 75).replace(\"e.g.\", \"\").replace(\"™\", \"\").replace(\"♥\", \"\").replace(\"½\", \"\").replace(\"★\", \"\").replace(\"&\", \"\").replace(\"◆\", \"\").replace(\"■\", \"\")\n",
        "#     merge_title = merge_title.reset_index()\n",
        "    print(merge_title)\n",
        "    \n",
        "    # ループで一行ずつ翻訳、Excelに入力＞ 一行ずつ翻訳、リストにしてSeries化\n",
        "    translator = Translator()\n",
        "    i = 0\n",
        "    title_en_list = []\n",
        "#     print(len(merge))\n",
        "#     print(len(merge_title))\n",
        "    while len(merge) > i: # 制限達したら、これパスしてXW転記もしないことにする。　一度エラー起きれば、リトライしてもずっとエラーだから、While要らない\n",
        "        try:\n",
        "#         print('a')\n",
        "        # lastRow_title2 = sht2.range('F4').end(-4121).row  # ATK H=タイトル列\n",
        "        # # lastRow_title2 = df2.iloc[:, 5].tail(n) # F= ５番目= 英訳の列  # tail(n)で、最下行を求める\n",
        "        # nextRow2 = lastRow_title2 + 1\n",
        "\n",
        "        # 文字列制限＋記号の置換をしてから、翻訳。\n",
        "#             def left(text, n):\n",
        "#                 return text[:n]\n",
        "#             merge\n",
        "#             merge_title = left(merge['タイトル'], 75).replace(\"e.g.\", \"\").replace(\"™\", \"\").replace(\"♥\", \"\").replace(\"½\", \"\").replace(\"★\", \"\").replace(\"&\", \"\").replace(\"◆\", \"\").replace(\"■\", \"\")\n",
        "#             print(merge_title)\n",
        "            # 英訳\n",
        "            merge_en = merge_title.iloc[i: i+1]#.apply( #一行ずつ翻訳\n",
        "#                 translator.translate, src='ja', dest='en').apply(getattr, args=('text',))\n",
        "#\n",
        "#             上記の２行で、17行目の余分な値が発生している。Series[]\n",
        "\n",
        "            print(merge_en)  # 1つのSeries　になる\n",
        "            title_en_list.append(merge_en)\n",
        "\n",
        "            # df2.iloc[nextRow2, 5] = merge_en # 5列目, nextrowの行から\n",
        "            # sht2.range('F{}'.format(nextRow2)).options(\n",
        "            #     pd.Series, expand='table', index=False, header=None).value = merge_en\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        except json.decoder.JSONDecodeError as e:\n",
        "            print(str(e) + ' json Decoder Error 発生。本日の上限を達した模様。次へ') #リトライ...')\n",
        "            break\n",
        "            # time.sleep(1)\n",
        "            # continue ここContinueのせいで、以降の作動にはいかず、次の検索フレーズループへ進む\n",
        "            \n",
        "#         break\n",
        "#     print(len(title_en_list)) #やはり１８行カウントされるから黒\n",
        "#     merge_en\n",
        "    title_en_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "4f9NYkYRs8Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    \n",
        "    # ここでSQLテーブルのタイトル列へ自動で移動する\n",
        "    title_en_list_sr = pd.Series(title_en_list, name='Title', index=None).reset_index(drop=True)#, inplace=True)#, index=None)#, name=None)\n",
        "    # merge_en.columns = 'Title'  # 列名をTitleにすることで、SQLのTitle列に追加される\n",
        "    title_en_list_sr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "OAg5SW1vs8R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # break\n",
        "    # lastRow_title1 = sht2.range('H4').end(-4121).row  # ATK H=タイトル列\n",
        "    # lastRow_title1 = df2.iloc[:, 7].tail(n) # H= 7\n",
        "    # nextRow = lastRow_title1 + 1\n",
        "\n",
        "    # URLとタイトルのDF=mergeを、to_sql\n",
        "    # merge（URLとタイトルのdf） にmainkey, categ_numのdfを加え、SQL。\n",
        "    main_categ_df = pd.DataFrame({'main key': mainKey, 'Category': categ_num},\n",
        "                                 index=[0, 1]) # index入れないとエラーになる　http://nishidy.hatenablog.com/entry/2016/03/10/015337\n",
        "    main_categ_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "7nSr7Fnzs8SH",
        "colab_type": "text"
      },
      "source": [
        "### main_categのインデックスを空白から数字にすると、横連結すると起きた ValueError: Shape of passed values is... というのが解決した"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "auQDUbOXs8SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "concat = pd.concat([merge, title_en_list_sr, main_categ_df], axis=1)\n",
        "# concat = pd.concat([merge, main_categ_df], axis=1)\n",
        "concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "PvP9k_OFs8SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concat = concat.fillna(method='pad')\n",
        "concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "4_I6cw5Os8Se",
        "colab_type": "text"
      },
      "source": [
        "### DF空箱にループ追加"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "dVFGmgrTs8Sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "list_df = list_df.append(concat, ignore_index=True)\n",
        "list_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Rudle2fcs8Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "    # リストも加えられる？ df を対象にできる？df のmergeによって、タイトルの重複を避けられるから、DFでやりたい\n",
        "    all_np = np.array([[merge], [title_en_list_sr], #]).T#,\n",
        "                       [main_categ_df]]).T\n",
        "#     all_np\n",
        "    all_np_df = pd.DataFrame(all_np)\n",
        "    all_np_df\n",
        "    \n",
        "    all_np_df.to_csv('all_np.csv')\n",
        "#     print()\n",
        "#     all_np.savetxt(r'all_np.csv', ab, delimiter=\",\", fmt=('%s, %f'))\n",
        "    all_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "zmNlv1CRs8S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    from ipysheet import from_dataframe, to_dataframe\n",
        "    sheet = from_dataframe(all_np)\n",
        "    sheet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "AmxM_PLgs8S_",
        "colab_type": "text"
      },
      "source": [
        "#### main key, Categoryの列を、他列の行数まで同じ値で埋め合わせるためfillna(pad)を使えると思ったが、Numpyでは無理みたい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "RHCwtjdQs8TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    all_np.fillna(method='pad')  # transpose()  # elem_img]) # src_list]\n",
        "    all_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "cUe8-w7ds8TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "DvqEa22rs8Td",
        "colab_type": "text"
      },
      "source": [
        "### ループ毎に加えていくのだが、np.arrayではなくconcatしたDFに。つまり空箱はDFで"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Gl7UxkQ3s8Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    # 行数合わないなら、np.arrayにfillna\n",
        "\n",
        "arr_title_url_id_ = np.r_[arr_title_url_id_, all_np]\n",
        "arr_title_url_id_ \n",
        "    \n",
        "#     break\n",
        "    # URL\n",
        "    # df2.iloc[nextRow, 46] = merge.iloc[:, 1]\n",
        "    # sht2.range('AT{}'.format(nextRow)).options(\n",
        "    #     pd.Series, expand='table', index=False, header=None).value = merge.iloc[:, 1] # url_list 　ここをDF.iloc　option dataframeのやつ\n",
        "    # タイトル\n",
        "    # df2.iloc[nextRow, 7] = merge.iloc[:, 0]\n",
        "    # sht2.range('H{}'.format(nextRow)).options(\n",
        "    #     pd.Series, expand='table', index=False, header=None).value = merge.iloc[:, 0]  # title_list\n",
        "\n",
        "    # sht2.range('F{}'.format(nextRow)).options(\n",
        "    #     pd.Series, expand='table', index=False, header=None).value = merge_en\n",
        "\n",
        "    # lastRow_title2 = df2.iloc[:, 7].tail(n)  # H= 7\n",
        "    # lastRow_title2 = sht2.range('H4').end(-4121).row\n",
        "\n",
        "    # mainKeyとcateg_numを、タイトル列の最下行(lastRow_title2)まで埋める＞SQLで行番号を判別、選択できるか\n",
        "    # 新たに加えたタイトル列と同じ数だけその２列を埋める。これ他のエクセル関数入った列のオートフィル処理の箇所にも使う\n",
        "    # mainKey\n",
        "    # df2.iloc[nextRow: lastRow_title2, 1] = mainKey\n",
        "    # sht2.range('B{}:B{}'.format(nextRow, lastRow_title2)).options(transpose=True).value = mainKey\n",
        "    # # print(mainKey)  # どのカテゴリかひと目で分かるようキーをB列に\n",
        "    # # カテゴリ番号\n",
        "    # # df2.iloc[nextRow: lastRow_title2, 0] = categ_num\n",
        "    # sht2.range('A{}:A{}'.format(nextRow, lastRow_title2)).options(transpose=True).value = categ_num\n",
        "    # print(categ_num) #A列に\n",
        "\n",
        "    # wb2.save() #ここで保存することで, df2 はループごとにATKを読み込み、重複対象も前ループのリサ結果が対象になる\n",
        "    # break # 2回繰り返し、url_list に２回めの取得結果を上書きしているのか、積み重ねているのか調べる\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "ymX28CVJs8Tn",
        "colab_type": "text"
      },
      "source": [
        "#### Dataframeの空箱ループ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "J_fhpV4Es8To",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_df = pd.DataFrame( columns=['A','B'] )\n",
        "\n",
        "for i in [0,1,2,3,4,5]:\n",
        "    tmp_se = pd.Series( [ i, i*i, i+i])#, index=list_df.columns )\n",
        "    list_df = list_df.append( tmp_se, ignore_index=True )\n",
        "\n",
        "print( list_df )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "zP0274Eys8Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_df = pd.DataFrame( columns=['A','B'] )\n",
        "\n",
        "for i in [0,1,2,3,4,5]:\n",
        "    tmp_se = pd.Series( [ i, i*i], index=list_df.columns )\n",
        "    list_df = list_df.append( tmp_se, ignore_index=True )\n",
        "\n",
        "print( list_df )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "sgnpGS6Ms8T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_title_url_id_ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "1dExI46Ys8UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ここで、全ループ取得分のDFを作る。\n",
        "all_df = pd.DataFrame(arr_title_url_id_)\n",
        "all_df\n",
        "\n",
        "# 重複除去>> 必要なし\n",
        "# app.books.open(\"C:/Users/Kazuki Yuno/AppData/Roaming/Microsoft/Excel/XLSTART/PERSONAL.XLSB\")\n",
        "# macro = app.macro('PERSONAL.XLSB!removeDup_singleCol')\n",
        "# macro()\n",
        "\n",
        "#\n",
        "# 他の関数列オートフィル　SQLで最下行まで\n",
        "# エクセル関数は、SQL内で新たに作るのか、PandasやPyで新たに作るのか、を決めた後にオートフィル\n",
        "# エクセルのオートフィルは、Pandasでは一行のみ完成すれば、あとはそれを全行埋める\n",
        "# fillna(method='')で前の行と同じ値にすれば良い？\n",
        "# 列間の計算をさせる\n",
        "\n",
        "\n",
        "# lastRow_sku = sht2.range('C4').end(-4121).row  # ここHにすると転記後の行だからズレが生じる。D も同じことが言えるか ＞言えない。この時点で数値が決まってるからOK\n",
        "# # ここは、此のファイルで何も表記されない（最初の）列を選ぶ。\n",
        "# lastRow_title3 = sht2.range('H4').end(-4121).row  # タイトル列\n",
        "# def autofill_atk():\n",
        "#     col_list = ['D', 'E', 'G', 'Y', 'Z', 'AD', 'AG', 'AH', 'AI', 'AJ', 'AU', 'AY', 'BI', 'BK', 'BL', 'BM', 'BN',\n",
        "#                 'BO', 'BP', 'BQ', 'BR', 'BS', 'BT', 'BU', 'BV', 'BW', 'BX']\n",
        "#     for col in col_list:  # DEG がタイトル関連、YZが重量、　ADが見込売値, AU~AYがヤフオク、 BK以降は利益計算\n",
        "#         try:\n",
        "#             sht2.range('{}{}'.format(col, lastRow_sku)).api.AutoFill(\n",
        "#                 sht2.range(\"{}{}:{}{}\".format(col, lastRow_sku, col, lastRow_title3)).api,\n",
        "#                 AutoFillType.xlFillDefault)\n",
        "#             time.sleep(0.5)\n",
        "#         except com_error as e:\n",
        "#             print(str(e) + ' が発生。ループから抜ける')\n",
        "#             break # ループ抜ける\n",
        "# autofill_atk()\n",
        "    #\n",
        "\n",
        "# SKU　　id の列をタイトル列の最終行まで抜き取り、それを一行ずつSKU生成の材料に使う\n",
        "# lastRow_sku = sht2.range('C4').end(-4121).row\n",
        "# nextRow_sku = lastRow_sku + 1\n",
        "# lastRow_url = sht2.range('AT4').end(-4121).row  # ATK AT＝URL列（オートフィル後）の最下行\n",
        "# id_col = sht2.range('AU{}:AU{}'.format(nextRow_sku, lastRow_title3)).value\n",
        "# df2（atklist）のid列を、エクセルでいうnextRow_skuの行から取得 #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ppvdQVgos8UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "5cCv8dAAs8UQ",
        "colab_type": "text"
      },
      "source": [
        "#### SKUを全ループ追加分を作成し、その列を横付け"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "temk2kVRs8UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_col = list_df['ID'] #.iloc[] # SKU\n",
        "id_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "kmabcRIas8UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sku_list = []\n",
        "# def left(text, n):\n",
        "# \treturn text[:n]\n",
        "def right(text, n): # https://qiita.com/ty21ky/items/111d8d636fe7f6e29621\n",
        "    return text[-n:]\n",
        "for id in id_col:  # ランダムID + ID + 日付\n",
        "    sku_list.append(right(str(uuid4()) + '-' + str(id) + datetime.now().strftime('-%Y%m-%d%H-%M%S'), 50))\n",
        "# SKUの列＝C\n",
        "# sht2.range('C{}'.format(str(nextRow_sku))).options(transpose=True).value = sku_list\n",
        "sr_sku = pd.Series(sku_list, name='SKU')\n",
        "sr_sku\n",
        "# merge, オーtフィルする列、sku_list, 全てDFにまとめ、一発で・to_sql\n",
        "# concatすることで、mergeの行数の分、df3の行数も増やしたい\n",
        "# これで一番最後にsr_titleをconcatしたいのだが、なんせ翻訳が制限で途中で中止される。\n",
        "# 他の列と行数が変わってしまう。その翻訳できなかった差分は、とりあえず何かしら値を入れたら良い。> fillna()\n",
        "# titleは fillna(0)で、df3 は前の行の値（mainkey）だから fillna(method='pad') ＞これ同時にできる？\n",
        "# concat = pd.concat([merge, sr_title, sr_sku]).fillna(0) # title列、未翻訳＝空白の行を0で埋める。https://deepage.net/features/pandas-manipulate-na.html#%E5%9F%BA%E6%9C%AC%E7%9A%84%E3%81%AA%E4%BD%BF%E3%81%84%E6%96%B9-1\n",
        "# 下にして"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "b5YzRvVts8Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "_LRvF3qZs8Up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global concat\n",
        "concat2 = pd.concat([list_df, sr_sku], axis=1) \n",
        "\n",
        "# ここでSKU列に「SKU」と列名を与える。なぜ0~4はNaN？\n",
        "concat2\n",
        "# 一行のエクセル関数DFを追加、下までフィル\n",
        "# global concat2\n",
        "# concat2 = pd.concat([concat, main_categ_df]).fillna(method='pad') #'ffill' と同等 # 空白を前の行で埋める https://riptutorial.com/ja/pandas/example/6188/%E4%B8%8D%E8%B6%B3%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E5%80%A4%E3%82%92%E5%9F%8B%E3%82%81%E8%BE%BC%E3%82%80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "qAm8uqtDs8Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ここでID出力。マクロ. Elems の場合は全てのIDを出力せず、追加されたIDを都度都度ファイルへ加えていく\n",
        "# このPyで追加したアイテムのIDだけでいい\n",
        "# macro = app.macro('PERSONAL.XLSB!OutputActiveID_Txt_elem') # 状態列が空白の行から全てのIDをテキストへ\n",
        "# macro()\n",
        "# shutil.move('C:/Users/Kazuki Yuno/Desktop/00.Myself/04.Buyer/1.利益計算/db_check_yahoo_elem.txt',\n",
        "#             'C:/Windows/System32/ScrapingTool_Init/sample_codes/db_check_yahoo_elem.txt')\n",
        "elems_id_txt = r'C:/Windows/System32/ScrapingTool_Init/sample_codes/zaico-fixcan/db_check_yahoo_elem.txt'\n",
        "id_col.to_csv(elems_id_txt,\n",
        "          header=None, index=None, sep=' ')#, mode='a') # mBall_elem_zaicoは、追加された分のIDの価格だけでいい\n",
        "\n",
        "# time.sleep(10) # 時間置かないと、elems_yahooでTxtファイルがないと言われることがある\n",
        "# wb2.save()\n",
        "# app.kill()\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "2upyYm2is8VB",
        "colab_type": "text"
      },
      "source": [
        "### 価格・説明文・状態の要素取得、エクセル表計算を参考にした計算をSQLで"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOtvM55r3CV7",
        "colab_type": "text"
      },
      "source": [
        "##### 古いVer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "dQGCWtdfs8VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def remove_space_htmlTag(s):\n",
        "    p = re.compile(r\"<[^>]*?>\") # htmlTagを削除\n",
        "    remove = p.sub(\"\", s)\n",
        "    space = re.sub(r'\\s+', ' ', remove).strip()  # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "    return space.replace('[', '').replace(']', '') # [] を置換\n",
        "\n",
        "\n",
        "def remove_space_htmlTag_pr(s): #もし日件の値なら＞これまでの置換、価格のみなら＞「税込～」の置換\n",
        "#     if s is string\n",
        "    p = re.compile(r\"<[^>]*?>\") # htmlTagを削除\n",
        "#     print('p '+str(p))\n",
        "    remove = p.sub(\"\", s)\n",
        "#     print('remove '+str(remove))\n",
        "    space = re.sub(r'\\s+', ' ', remove).strip()#.sub(r'(円（税込\\d+円）)', remove) # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "#     print('space '+str(space))\n",
        "#     space = re.sub(r'(円（税込\\d+円）)', space)\n",
        "#     space = re.sub(r'(円（税込\\d{4,5,6}円）)', space)\n",
        "#     print('space '+str(space))\n",
        "#     type(s)\n",
        "    return space.replace('[', '').replace(']', '').replace('円（税 0 円） ', '')#.sub(r'(円（税込\\d{4,5,6}円）)', space)\n",
        "\n",
        "\n",
        " # mergeのURL列から、新たにitemID 列を導き出す\n",
        "def extract_key(url): # URLからキー（URLの末尾のISBN）を抜き出す。\n",
        "    m = re.search(r'/([^/]+)$', url) # /([^/]+)$\n",
        "    return m.group(1)\n",
        "\n",
        "\n",
        "# def normalize_spaces(s):\n",
        "#     \"\"\"\n",
        "#     連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "#     \"\"\"\n",
        "#     return re.sub(r'\\s+', ' ', s).strip()\n",
        "#\n",
        "\n",
        "# def check_if_Excel_runs():\n",
        "    # try:\n",
        "    #     win32com.client.GetActiveObject(\"Excel.Application\")\n",
        "    #     # If there is NO error at this stage, Excel is already running\n",
        "    #     print('Excel is running, please close first')\n",
        "    #     xw.Book.close() # 全てのブックを消去\n",
        "    #     xw.App.kill()\n",
        "    #     sys.exit() # これは\n",
        "    # except:\n",
        "    #     print('Excel is NOT running, this is good!')\n",
        "    # return\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo1TnYtr3V6H",
        "colab_type": "text"
      },
      "source": [
        "#### 新しいVer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "j9q7HRhvs8VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_space_htmlTag(s):\n",
        "    p = re.compile(r\"<[^>]*?>\") # htmlTagを削除\n",
        "    remove = p.sub(\"\", s)\n",
        "    space = re.sub(r'\\s+', ' ', remove).strip()  # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "    return space.replace('[', '').replace(']', '') # [] を置換\n",
        "\n",
        "\n",
        "def remove_space_htmlTag_pr(s): # 価格用\n",
        "    p = re.compile(r\"<[^>]*?>\")\n",
        "    remove = p.sub(\"\", s)\n",
        "    remove = re.sub(r'\\s+', ' ', remove).strip()#.sub(r'(円（税込\\d+円）', remove)\n",
        "    p = re.compile(r'(円（税込 \\d+,\\d+ 円）)')  # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "    remove = p.sub(\"\", remove)\n",
        "    # space = re.sub(r'(円（税込\\d+円）)', space)\n",
        "    return remove.replace('[', '').replace(']', '').replace('円（税 0 円） ', '')\n",
        "\n",
        "\n",
        " # mergeのURL列から、新たにitemID 列を導き出す\n",
        "def extract_key(url): # URLからキー（URLの末尾のISBN）を抜き出す。\n",
        "    m = re.search(r'/([^/]+)$', url) # /([^/]+)$\n",
        "    return m.group(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "GbdeZarWs8Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv # は要らない\n",
        "\n",
        "# from sample_codes import elems_yahoo4 as elyahoo\n",
        "el_csv = r'C:/Users/kazuki_juno/Desktop/00.Myself/04.Buyer/1.利益計算/db_yahoo_elements.csv'\n",
        "with open(el_csv, 'w', encoding='utf-8-sig', newline='', errors='ignore') as f:\n",
        "    # elyahoo.main(f, el_csv, concat2)\n",
        "    #     el_main(f, el_csv, elems_id_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "UIMK7Tbds8Vw",
        "colab_type": "text"
      },
      "source": [
        "#### 価格のみ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ufBrVMtAs8Vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "2P4QuDWZs8V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv # は要らない\n",
        "el_csv = r'C:/Users/kazuki_juno/Desktop/00.Myself/04.Buyer/1.利益計算/db_yahoo_elements.csv'\n",
        "with open(el_csv, 'w', encoding='utf-8-sig', newline='', errors='ignore') as f:\n",
        "    \n",
        "    # def el_main(f, el, txt):\n",
        "    writer = csv.writer(f)\n",
        "    with open(elems_id_txt) as f: #\n",
        "        page_id_list = [str(row) for row in f]\n",
        "    # img_list = []\n",
        "    # id_list = []\n",
        "    # arr = np.empty([0, 2])\n",
        "    arr_descon = np.empty([0, 3]) # ここは３列か\n",
        "    arr_img = np.empty([0, 2]) # 0, 2 だと２列分のみ＞ \n",
        "    arr_pr = np.empty([0, 2])\n",
        "    # print(arr)\n",
        "    for page_id in page_id_list[:7]:#[347:352]:#[:10]:\n",
        "        print(page_id)\n",
        "        url = f'https://page.auctions.yahoo.co.jp/jp/auction/{page_id}'\n",
        "#         try:\n",
        "        res = requests.get(url.strip())\n",
        "        res.raise_for_status()\n",
        "        soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "\n",
        "#         price = soup.select(\"dl > dd.Price__value:not('.Price__tax', '.Price__priceDown')\") #[0] #.next_sibling.strip() # > span.Price__tax')\n",
        "#         price = soup.find_all(\"dl > dd.Price__value:not('.Price__tax, .Price__priceDown')\") # 動くがすべて消える # クラス名一つずつ'で囲ってもダメ\n",
        "        \n",
        "        # https://stackoverflow.com/questions/48336544/beautifulsoup-html-except-tag\n",
        "#         price = soup.find_all(\"dl\", attrs= {'class':'Price__value'})#[1].text\n",
        "\n",
        "        # https://stackoverflow.com/questions/58310935/select-all-divs-except-ones-with-certain-classes-in-beautifulsoup\n",
        "#         classToIgnore = [\"Price__tax\", \"Price__priceDown\"] #\n",
        "# #         price = soup.select('dl > dd.Price__value', class_=lambda x: x not in classToIgnore) # find_allだとすべて消える\n",
        "#         for price in soup.select('dl > dd.Price__value', class_=lambda x: x not in classToIgnore):\n",
        "#             price.decompose()\n",
        "#         price = soup.select('dl > dd.Price__value')\n",
        "        \n",
        "        from bs4 import NavigableString\n",
        "#         result = soup.find_all(\"dd\",{\"class\":\"Price__value\"})\n",
        "# #         result = soup.select(\"dl > dd.Price__value\")\n",
        "#         print(result)\n",
        "#         price = [element for element in result if isinstance(element, NavigableString)] # \n",
        "#         print(price)\n",
        "#         price = price[0:1]\n",
        "#         print(price)\n",
        "        #textに絞れないか\n",
        "\n",
        "        # ネストされていない要素（税金価格や値引き文抜きの価格要素）のみFind all https://stackoverflow.com/questions/54259105/beautifulsoup4-find-all-non-nested-matches\n",
        "        all_fetched = []\n",
        "        fetched = soup.find('dd', class_='Price__value')\n",
        "\n",
        "        while fetched is not None:\n",
        "            all_fetched.append(fetched)\n",
        "            try:\n",
        "                last = list(fetched.descendants)[-1]\n",
        "            except IndexError:\n",
        "                break\n",
        "            fetched = last.findNext('dd', class_='Price__value')\n",
        "        print(all_fetched)\n",
        "        \n",
        "        \n",
        "        price2 = remove_space_htmlTag_pr(str(all_fetched))\n",
        "#         price2 = remove_space_htmlTag_pr(str(price))\n",
        "#         price2 = remove_space_htmlTag_pr(str(price))\n",
        "#         print(price2)\n",
        "\n",
        "        # pr_list.append(elems_d)\n",
        "#         for price2 in price2_all:\n",
        "#             print(price2.contents[1].strip())\n",
        "\n",
        "            \n",
        "        日件 = soup.select('.Count__number')\n",
        "        日件2 = remove_space_htmlTag_pr(str(日件))\n",
        "        # print(日件2)\n",
        "        \n",
        "        if '終了' in 日件2:  # 終了品は elems=価格 を空白に\n",
        "            # print(日件2)\n",
        "            price2 = ', '  # 空白のみだと、「, 」で分割する時エラー起きる\n",
        "            print(price2)  # + ' 終了')\n",
        "\n",
        "        else:  # 出品中なら\n",
        "            pr_title = soup.select('dt[class=\"Price__title\"]')\n",
        "            pr_title2 = remove_space_htmlTag_pr(str(pr_title))\n",
        "            # print(pr_title2)\n",
        "            if '現在価格' not in pr_title2:  # 現在価格が無い＝即決価格のみなら\n",
        "                price2 = ', ' + price2  # 価格の手前\n",
        "                print(price2)  # + ' 即決のみ')\n",
        "            else:  # 現在価格あるなら\n",
        "                print(price2) \n",
        "\n",
        "#         break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "4sysEfwDs8WE",
        "colab_type": "text"
      },
      "source": [
        "##### remove_space_htmlTagの挙動を一つずつ確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "W6uvfZNrs8WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    for page_id in page_id_list[15:]:#[347:352]:#[:10]:\n",
        "        print(page_id)\n",
        "        url = f'https://page.auctions.yahoo.co.jp/jp/auction/{page_id}'\n",
        "#         try:\n",
        "        res = requests.get(url.strip())\n",
        "        res.raise_for_status()\n",
        "        soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "        price = soup.select('dl > dd.Price__value')\n",
        "        print(price)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "tHLDKFZ7s8WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        price = str(price)\n",
        "        p = re.compile(r\"<[^>]*?>\") # htmlTagを削除するためにパターンをコンパイル\n",
        "    #     print('p '+str(p))\n",
        "        remove = p.sub(\"\", price) # ここでパターンに一致したものは空白に\n",
        "        print('remove '+str(remove))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "5zYSYByws8Wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        \n",
        "        space = re.sub(r'\\s+', ' ', remove).strip()\n",
        "        print(space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Qb19du90s8Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        # ここが問題。\n",
        "\n",
        "        p = re.compile(r'(円（税込 \\d+,\\d+ 円）)') # 連続する空白を1つのスペースに置き換え、前後の空白を削除した新しい文字列を取得する。\n",
        "        remove = p.sub(\"\", space) \n",
        "        print(remove)\n",
        "#         print('space '+str(space))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "8aKmgQKNs8Wo",
        "colab_type": "text"
      },
      "source": [
        "#### 税込 \\d+ だと、数値int64でないといけないかも、11,620のように 間に,があるとマッチしないか "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "7YJNEW-gs8Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qaOVMK6s8Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        #     space = re.sub(r'(円（税込\\d+円）)', space)\n",
        "        #     space = re.sub(r'(円（税込\\d{4,5,6}円）)', space)\n",
        "        #     print('space '+str(space))\n",
        "        #     type(s)\n",
        "        space = remove.replace('[', '').replace(']', '').replace('円（税 0 円） ', '')#.sub(r'(円（税込\\d{4,5,6}円）)', space)\n",
        "        print(space)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q22IIpvckBrn",
        "colab_type": "text"
      },
      "source": [
        "#### 価格とその他要素の取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "iQpd6O2js8W9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv # は要らない\n",
        "el_csv = r'C:/Users/kazuki_juno/Desktop/00.Myself/04.Buyer/1.利益計算/db_yahoo_elements.csv'\n",
        "with open(el_csv, 'w', encoding='utf-8-sig', newline='', errors='ignore') as f:\n",
        "    \n",
        "    # def el_main(f, el, txt):\n",
        "    writer = csv.writer(f)\n",
        "    with open(elems_id_txt) as f: #\n",
        "        page_id_list = [str(row) for row in f]\n",
        "    # img_list = []\n",
        "    # id_list = []\n",
        "    # arr = np.empty([0, 2])\n",
        "    arr_descon = np.empty([0, 3]) # ここは３列か\n",
        "    arr_img = np.empty([0, 2]) # 0, 2 だと２列分のみ＞ \n",
        "    arr_pr = np.empty([0, 2])\n",
        "    # print(arr)\n",
        "    for page_id in page_id_list:#[347:352]:#[:10]:\n",
        "        print(page_id)\n",
        "        url = f'https://page.auctions.yahoo.co.jp/jp/auction/{page_id}'\n",
        "        try:\n",
        "            res = requests.get(url.strip())\n",
        "            res.raise_for_status()\n",
        "            soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "            # 説明文/description\n",
        "            #scrape(soup, writer, url, arr) #, img_list, id_list, arr)\n",
        "            elems = soup.select(\n",
        "                '#adoc > div.ProductExplanation__body.highlightWordSearch > div.ProductExplanation__commentArea > div')\n",
        "            elems_d = remove_space_htmlTag(str(elems))\n",
        "            print(elems_d)\n",
        "\n",
        "            #状態/condition\n",
        "            elems1 = soup.select(\n",
        "                '#adoc > div.ProductExplanation__body.highlightWordSearch > div.ProductExplanation__tableArea > table > tbody > tr:nth-child(2) > td > ul > li')  # [0].extract()\n",
        "            # print(elems1)\n",
        "            elems_c = remove_space_htmlTag(str(elems1))\n",
        "            print(elems_c)\n",
        "\n",
        "            # 画像\n",
        "            elem_img = soup.select(\"div[class='ProductImage__inner'] img\")\n",
        "            for tmp in elem_img:\n",
        "                # global src_fact\n",
        "                src_fact = tmp.attrs[\"src\"]  # attrsを用いてhtmlのsrc=の中身をsrc_factに格納していきました。\n",
        "#                 print(src_fact)\n",
        "                # if src_fact == []:\n",
        "                #     print(\"画像が見つかりません。。。\")\n",
        "                # else:\n",
        "                page_id_for_scrape = url.split('/')[-1]\n",
        "                list = [elems_d, elems_c, page_id_for_scrape]\n",
        "                writer.writerow(list)\n",
        "                time.sleep(0.5)\n",
        "                \n",
        "                img_np = np.array([[page_id_for_scrape], [src_fact]]).T  # transpose()  # elem_img]) # src_list]\n",
        "                arr_img = np.r_[arr_img, img_np]\n",
        "\n",
        "                \n",
        "            # 価格\n",
        "            price = soup.select('dl > dd.Price__value')#[0]\n",
        "            price2 = remove_space_htmlTag_pr(str(price))\n",
        "            # print(price2)\n",
        "            # pr_list.append(elems_d)\n",
        "            日件 = soup.select('.Count__number')\n",
        "            日件2 = remove_space_htmlTag_pr(str(日件))\n",
        "            # print(日件2)\n",
        "            if '終了' in 日件2:  # 終了品は elems=価格 を空白に\n",
        "                # print(日件2)\n",
        "                price2 = ', '  # 空白のみだと、「, 」で分割する時エラー起きるから\n",
        "                print(price2)  # + ' 終了')\n",
        "\n",
        "            else:  # 出品中なら\n",
        "                pr_title = soup.select('dt[class=\"Price__title\"]')\n",
        "                pr_title2 = remove_space_htmlTag_pr(str(pr_title))\n",
        "                # print(pr_title2)\n",
        "                if '現在価格' not in pr_title2:  # 現在価格が無い＝即決価格のみなら\n",
        "                    price2 = ', ' + price2  # 価格の手前\n",
        "                    print(price2)  # + ' 即決のみ')\n",
        "                else:  # 現在価格あるなら\n",
        "                    print(price2)  # + ' 現在') # ここは最初のprice2になる\n",
        "\n",
        "        except requests.exceptions.HTTPError as err:\n",
        "            print(err)\n",
        "            elems_d = ''# httpエラーのIDが飛ばされていたので\n",
        "            elems_c = ''\n",
        "            src_fact = ''\n",
        "            price2 = ''\n",
        "\n",
        "        # try とexcept のスコープ両方に入れいてたが、zaicoは双方の後に、以下を入れてる\n",
        "        page_id_for_scrape = url.split('/')[-1]\n",
        "\n",
        "        list = [elems_d, elems_c, page_id_for_scrape]\n",
        "        writer.writerow(list)\n",
        "\n",
        "        dc_np = np.array([[page_id_for_scrape], [elems_d], [elems_c]]).T  # transpose()  # elem_img]) # src_list]\n",
        "        arr_descon = np.r_[arr_descon, dc_np]\n",
        "        \n",
        "#         img_np = np.array([[page_id_for_scrape], [src_fact]]).T  # transpose()  # elem_img]) # src_list]\n",
        "#         arr_img = np.r_[arr_img, img_np]\n",
        "        \n",
        "        pr_np = np.array([[page_id_for_scrape], [price2]]).T  # transpose()  # elem_img]) # src_list]\n",
        "        arr_pr = np.r_[arr_pr, pr_np]\n",
        "        \n",
        "        time.sleep(1)\n",
        "    \n",
        "#         break\n",
        "        \n",
        "    img_df = pd.DataFrame(arr_img)\n",
        "    print(img_df)\n",
        "    img_df.to_csv('df_img.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "RFtpWjh1s8XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # DF化\n",
        "    # 説明、状態の DF化\n",
        "    descon_df = pd.DataFrame(arr_descon, columns=['ID', '説明', '状態']).iloc[:, 1:3]#.column  # 0. 1行目のみ\n",
        "    #     descon_df.column = ['説明', '状態']\n",
        "    descon_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "fGVgkVibs8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # def img_spread(arr):  # (img_list):\n",
        "    img_df = pd.DataFrame(arr_img, columns=['ID', '画像'])#.iloc[:, 1:]\n",
        "    img_df\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "u2R4kAD8s8XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    img_df.columns = ['ID', '画像'] # 列名指定 # ここに価格２列を追加\n",
        "    img_df\n",
        "#     img_df.to_csv('df_img.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "BMIQioZDs8XU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def f(a): # 単なるGroupBy, apply ではなく、関数 f を組むことで、画像URLを一列に集約するだけでなく、各列に分割までできた  # https://ja.stackoverflow.com/questions/24845/python%E3%81%AEpandas%E3%81%A7-%E7%B8%A6%E6%8C%81%E3%81%A1%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E6%A8%AA%E6%8C%81%E3%81%A1%E3%81%AB%E3%81%99%E3%82%8B%E3%82%88%E3%81%84%E6%96%B9%E6%B3%95%E3%82%92%E6%95%99%E3%81%88%E3%81%A6%E3%81%8F%E3%81%A0%E3%81%95%E3%81%84\n",
        "        a.index = [0 for i in range(len(a))]\n",
        "        del a['ID'] # 列名指定\n",
        "        out = a[0:1]\n",
        "        for i in range(1, len(a)):\n",
        "            out = out.join(a[i:i + 1], rsuffix='{0}'.format(i))\n",
        "        return out\n",
        "\n",
        "    global grped # ここでiloc かける\n",
        "    grped = img_df.groupby(img_df['ID'], sort=False).apply(f)\n",
        "    grped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Beqxm6t7s8Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    grped = grped.iloc[:, 1:8].reset_index(drop=True) #, inplace=True) # おまけに、列名まで生成されてる!　ここで順を崩さないように\n",
        "    # return grped\n",
        "    grped  # https://stackoverflow.com/questions/48044542/groupby-preserve-order-among-groups-in-which-way\n",
        "    # grped2 = grped.iloc[::-1] # 上下反転　\n",
        "    # grped2.to_csv('merge_imgs2.csv') # これは列がバラバラのまま\n",
        "\n",
        "    # elements.csvのID順は、ATKのそれと同じか？売り切れ品の要素も空白として記録してる？\n",
        "    # cols = ['ゆ', 'の', 'ID']\n",
        "    # id_df = pd.read_csv(el, # ここatk のID 列でもいい\n",
        "    #                     header=None, names=cols).iloc[:, 2] # .reset_index() # , index='ID') # , columns=['ID'])\n",
        "    # # id_df = pd.read_excel(atk, 'Sheet1', usecols=['ID_y'], skiprows=2, encoding='cp932')\n",
        "    # print(id_df)\n",
        "    # concat = pd.concat([id_df, grped], axis=1) # p.263 これ数値のみ？ 共通の越インデックスはあるが\n",
        "    # id_df をつくりmergeさせるのは、grped のIDの並びがバラバラになっているのを、元のATK記載のIDリストの並びに戻すため\n",
        "    # バラバラではなく、逆順になっていた\n",
        "    # 2行分のズレが生じてるのは、このmergeによるものなのでは？では、マージではなく, 逆に並べる動作をすれば\n",
        "    # merge = pd.merge(id_df, grped, on='ID', how='outer') # 外部結合なら、どちらかに無い値はNaNと表示される\n",
        "    # print(merge)\n",
        "#     grped.to_csv('merge_imgs3.csv')\n",
        "    # update_atk(el, grped)\n",
        "    # mBall_elem_zaicoは、新たに追加されたID分の価格を取得できればいい\n",
        "\n",
        "# img_spread()\n",
        "\n",
        "\n",
        "# def update_atk(el, grouped):\n",
        "#     app = xw.App(visible=False)  # 新規アプリ実行環境を作成する\n",
        "#     wb1 = app.books.open(el)\n",
        "#     app.books.open(\"C:/Users/Kazuki Yuno/AppData/Roaming/Microsoft/Excel/XLSTART/PERSONAL.XLSB\")\n",
        "#     # macro = app.macro('PERSONAL.XLSB!elementsfromBS4')\n",
        "#     # macro()\n",
        "#     wb1.save()\n",
        "#\n",
        "#     atk = r\"C:/Users/Kazuki Yuno/Desktop/00.Myself/04.Buyer/1.利益計算/AtackList_Buyer43.xlsx\"\n",
        "#     wb2 = app.books.open(atk)\n",
        "#     # af_elems.autofill(atacklist)\n",
        "#     # def el2at(el, atk, grped):\n",
        "#         # 説明文、状態、画像、価格2種類、その他利益計算の列全て\n",
        "#     sht1 = wb1.sheets[0]  # (1)にしていたが\n",
        "#     sht2 = wb2.sheets[0]\n",
        "#\n",
        "#     lastRow1 = sht1.range('C1').end(-4121).row # Aにしていたが、今回のHTTPエラー時は空白ができることで、最下行はID列＝Cで。\n",
        "#     # nextRow1 = lastRow1 + 1\n",
        "#     lastRow2 = sht2.range('AZ4').end(-4121).row  # ATK 状態列＝AZの最下行\n",
        "#     nextRow2 = lastRow2 + 1\n",
        "#     # 生成したCSVからタイトル、URL, 画像URLをATKへ、最下行の下の行から追加\n",
        "#     # col_list = ['G','I']\n",
        "#     # for col in col_list:\n",
        "#     # 説明と状態\n",
        "#     desc = sht1.range('A1:A{}'.format(str(lastRow1))).options(ndim=2).value\n",
        "#     sht2.range('J{}'.format(str(nextRow2))).value = desc\n",
        "#     condi = sht1.range('B1:B{}'.format(str(lastRow1))).options(ndim=2).value\n",
        "#     sht2.range('AZ{}'.format(str(nextRow2))).value = condi\n",
        "#     # col_list = ['R','S','T','U','V']\n",
        "#     # i = 2 # merge の３列目から\n",
        "#     # for col, i in zip(col_list, range(2, 7)): # これで、２のときはR, ３のときはS、となる # https://uxmilk.jp/13726\n",
        "#     # for col, i in zip(range(13, 18), range(2, 7)):\n",
        "#     # while i < 7:\n",
        "#\n",
        "#     # 画像、通常版\n",
        "#     sht2.range('P{}'.format(nextRow2)).options(\n",
        "#         pd.DataFrame, expand='table', index=False, header=None).value = grouped.iloc[:, 1:8] # mergeの１－７列目に画像URLがある。8, 9 まであるアイテムも。\n",
        "    # これまでのアイテムの画像データを一新＞ 4行目から\n",
        "    # my_values = merge.iloc[:, 1:8]\n",
        "    # sht2.range('P4').options(\n",
        "    #     pd.DataFrame, expand='table', index=False, header=None).value = my_values  # index=False\n",
        "\n",
        "    # el2at(wb1, wb2, grouped)\n",
        "\n",
        "    # 次のPricesチェック(zaico.py )のため, output ID\n",
        "    # zaico.py もつなげる ここはzaicoと繋がる必要はない。価格取得だけで良い\n",
        "    # import された時はfixCancel動かさない、などの設定\n",
        "    # 全ての行のIDを出力\n",
        "    #\n",
        "    # macro = app.macro('PERSONAL.XLSB!OutputActiveID_Txt')\n",
        "    # macro()\n",
        "    # shutil.move('C:/Users/Kazuki Yuno/Desktop/00.Myself/04.Buyer/1.利益計算/db_check_yahoo3.txt',\n",
        "    #             'C:/Windows/System32/ScrapingTool_Init/sample_codes/db_check_yahoo3.txt')\n",
        "    # wb2.save() # 読み取り専用の状態だと、保存できずエラーで終わる\n",
        "    # wb1.close()\n",
        "    # wb2.close()\n",
        "    # app.kill()\n",
        "\n",
        "    # 仕入先をスクレイプするごとに価格チェックすることになるから、ここは繋げない。最後に一括で価格やればいい\n",
        "\n",
        "    # from sample_codes import zaico_yahoo as zyahoo  # if name == main は、\n",
        "    # pr_csv = 'C:/Users/Kazuki Yuno/Desktop/00.Myself/04.Buyer/1.利益計算/db_check_yahoo4.csv'\n",
        "    # with open(pr_csv, 'w', encoding='utf-8-sig', newline='', errors='ignore') as f2:\n",
        "    #     zyahoo.main(f2, pr_csv)\n",
        "    #     # pr_main(f2, pr_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "cju5zglxs8Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    #  価格のDF化\n",
        "    pr_df = pd.DataFrame(arr_pr, columns=['ID','価格2種'])\n",
        "    pr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "UfLXFK4vs8Xw",
        "colab_type": "text"
      },
      "source": [
        "#### 下記は「税込」の箇所が置換できなかった時。７番目の価格が上では無いのが気がかり。29000円。。＞＞単に、売れただけ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "0YpXvKGDs8Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    #  価格のDF化\n",
        "    pr_df = pd.DataFrame(arr_pr, columns=['ID','価格2種'])\n",
        "    pr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "JXvW-unos8X0",
        "colab_type": "text"
      },
      "source": [
        "#### https://stackoverflow.com/questions/57463127/splitting-a-column-in-dataframe-using-str-split-function\n",
        "#### DFの列をSplitしながら生成された列の名を割り当てる方法がいくつか"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "HVtAn218s8X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    #     print(pr_df)\n",
        "    pr_df[['現在価格', '即決価格']] = pr_df['価格2種'].str.split(', ', expand=True) #.rename({0: 'First_Name', 1: 'Second_Name'})], axis=1)\n",
        "    pr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "bpT9emycs8X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    pr_df2 = pr_df.iloc[:, [2, 3]]  # drop([1], axis=1)\n",
        "    \n",
        "#     pr_df2.column = ['ID', '現在価格', '即決価格'] \n",
        "#     ここコメントアウトする2つのうち一つエラー消える\n",
        "\n",
        "    pr_df2  # 0, 2, 3 列目のみ表示\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "v_l7xaz4s8YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    pr_csv = 'C:/Users/kazuki_juno/Desktop/00.Myself/04.Buyer/1.利益計算/db_check_yahoo4.csv'\n",
        "    pr_df2.to_csv(pr_csv, header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "bPXEJ9CCs8YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    concat3 = pd.concat([concat2, descon_df, grped, pr_df2], axis=1) #ここが問題\n",
        "                         # 説明と状態、画像、価格\n",
        "    concat3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "_hn5DNpNs8YS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # # sql から追加した分を読み取る？\n",
        "    # # 価格を含めたDFを、後の現在価格の列を用いて計算するため、\n",
        "    # sql_df = pd.read_sql()\n",
        "\n",
        "    # 一行の数式を設定後、設定後の列をdf[]で表し、新たに数式を設定するのでOK か\n",
        "    # 一度dfにしないといけなくなるから、df[]は要らない\n",
        "    # 価格系、これはzaico_yahooへ移行\n",
        "    現在価格 = concat3['現在価格']#.iloc[0]\n",
        "    即決価格 = concat3['即決価格']#.iloc[0]\n",
        "    # 相場価格 = IF(AX8=0, AV8*3, AX8*1.5) # AX 即決価格、AV= 現在価格 # 両者とも、Zaicoした後にわかること\n",
        "    即決価格"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "3Nzg8uhEs8YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "現在価格"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "4LzQ-89ls8Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concat3['相場価格'] = int(concat3['現在価格']) / int(concat3['即決価格'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "RsRYPlHzs8Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(concat3['即決価格'].dtype)\n",
        "print(即決価格.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "1dca1mjDs8Yv",
        "colab_type": "text"
      },
      "source": [
        "#### 列ごとReplace, この際、strを入れることで正常に置換できた（なぜかは不明"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "u-QAnWOls8Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\n",
        "即決価格 = 即決価格.str.replace(' ', '').str.replace(' ', '').str.replace(',', '') #({' ': '', ',': ''}) #.astype('int64'))\n",
        "print(即決価格)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "qD2RMIBws8Y4",
        "colab_type": "text"
      },
      "source": [
        "#### astype(float64)は駄目だったので、to_numeric()で解決　"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "CRJ4aJF2s8Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(即決価格.astype('int64'))\n",
        "print(pd.to_numeric(即決価格)) #astype('int64'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "A3wTD44es8Y9",
        "colab_type": "text"
      },
      "source": [
        "#### まとめ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "t1E_1PyPs8Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "即決価格 = pd.to_numeric(concat3['即決価格'].str.replace(' ', '').str.replace(',', ''))\n",
        "print(即決価格)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGi8skr9Cbyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "現在価格 = pd.to_numeric(concat3['現在価格'].str.replace(' ', '').str.replace(',', ''))\n",
        "print(現在価格)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA6dFUsPAWx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concat3['相場価格'] = 現在価格 / 即決価格\n",
        "相場価格 = concat3['相場価格']\n",
        "print(相場価格)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-k4D5hpNUqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 即決価格.isnull()\n",
        "テスト = 現在価格*3\n",
        "print(テスト) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g5jOiHfFXIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import math\n",
        "# x = float('nan')\n",
        "concat3['相場価格'] = 現在価格* 3 if 即決価格.isnull() else 現在価格* 1.5\n",
        "相場価格 = concat3['相場価格']\n",
        "print(相場価格)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "No6Y2faos8ZJ",
        "colab_type": "text"
      },
      "source": [
        "#### 置換 ' 49,000'から 空白をなくす, かつ整数intにする. 列ごとする方法は？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "QcAxD6Gis8Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "    自己設定価格 = 0\n",
        "    最高販売価格 = 0 if not str(max(相場価格, 自己設定価格)).isnumeric() else max(相場価格, 自己設定価格)\n",
        "    最高販売価格\n",
        "    # もし最大値が数値でないなら 0, 数値なら最大値\n",
        "    #.isnumeric() # IFERROR(MAX(AD8,Q8,AF8),0) # AD相場価格 Q AF自己認定価格"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "xVSuNd0Ys8Z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    最安仕入価格 = min(即決価格) # 以降は、他ECから取得するようになったら　,\n",
        "                    # 落札相場価格,仕入れ値上限, 価格_r, 価格_a, 価格_m, 価格_o)\n",
        "                        #AN, AW8,AX8,AY8,AR8,BC8,BF8)\n",
        "    最安仕入価格"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "ngU1ne4es8Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# これはURL列から抽出\n",
        "希望利益率 = 25\n",
        "# =ROUNDDOWN(AH8*0.861-(AH8*BS8/100)-BL8,1) # AH最高売値 BS希望利益率 BL送料"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "bnQ_7QXRs8aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    仕入送料 = 1000 #\n",
        "    # 重量、ounce, pound, kg は、elems_yahoo4で取得するから、恐らく後で移行する\n",
        "    ounce = 0\n",
        "    pound = 0\n",
        "    kg = 0.7 # ある列の計算式\n",
        "    # integrated = if(ounce>0, ounce*0.03, if(pound>0,pound*0.45, if(kg>0,kg)))\n",
        "    integrated = ounce * 0.03 if ounce > 0 else pound * 0.45 if pound > 0 else kg # if kg > 0 # https://note.nkmk.me/python-if-conditional-expressions/\n",
        "    # integrated = if(ounce>0, ounce*0.03, if(pound>0,pound*0.45, if(kg>0,kg)))\n",
        "    # if ounce > 0:\n",
        "    #     integrated = ounce * 0.03\n",
        "    # elif pound > 0:\n",
        "    #     integrated = pound * 0.45\n",
        "    # else kg > 0:\n",
        "    #     integrated = kg\n",
        "    # integ_col = df['integrated'] # 下記、df[integrated] 省略したい\n",
        "    送料設定 = \"0~0.3kg\" if integrated<0.3 else \"0.3~0.5kg\" if integrated<0.5 else \"0.5~0.8kg\" if integrated<0.8 else\\\n",
        "        \"0.8~1.0kg\" if integrated<1 else \"1.0~1.5kg\" if integrated<1.5 else \"1.5~2.0kg\" if integrated<2 else\\\n",
        "            \"2.0~2.5kg\" if integrated<2.5 else \"2.5~3.0kg\" if integrated<3 else \"3.5kg\" if integrated<3.5 else\\\n",
        "            \"4.0kg\" if integrated<4 else \"4.5kg\" if integrated<4.5 else \"5.0kg\" if integrated<5 else\\\n",
        "            \"5.5kg\" if integrated < 5.5 else \"6.0kg\" if integrated < 6 else \"7.0kg\" if integrated< 7 else\\\n",
        "            \"8.0kg\" if integrated < 8 else \"9.0kg\" if integrated< 9 else '10.0kg以上' # Z = integrated\n",
        "    # 送料設定_col = df['送料設定']\n",
        "    送料 = 935 if 送料設定 == \"0~0.3kg\" else 1235 if 送料設定 == \"0.3~0.5kg\" else 1685 if 送料設定 == \"0.5~0.8kg\" else\\\n",
        "        1985 if 送料設定 == \"0.8~1.0kg\" else 2525 if 送料設定 == \"1.0~1.5kg\" else 3065 if 送料設定 == \"1.5~2.0kg\" else 5000\n",
        "    # 後で 1985 if 送料設定 == \"2.0~2.5kg\" else 2525 if 送料設定 == \"2.5~3.0kg\" else 3065 if 送料設定 == \"1.5~2.0kg\" else\\\n",
        "\n",
        "    最高売値 = 最高販売価格 + 送料 + 仕入送料  # AG8+BL8+BI8\n",
        "    最高売値"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "EcyEiKFis8aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "    粗利 = 最高売値 - 最安仕入価格  # AH8-AI8\n",
        "    出品料 = 0 # なし\n",
        "    # 最高売値col = df['最高売値']\n",
        "    落札料 = 最高売値* 0.1\n",
        "    Paypal = round(最高売値* 0.039, 1)\n",
        "    支出合計 = sum(送料 + 出品料 + 落札料 + Paypal + 仕入送料)\n",
        "\n",
        "    仕入れ値上限 = round(最高売値 * 0.861 - (最高売値 * 希望利益率 / 100) - 送料, 1)\n",
        "\n",
        "    営業利益 = 粗利 - 支出合計\n",
        "    利益率 = round(最高売値 / 営業利益* 100, 1)\n",
        "    販売額 = round((最安仕入価格 + 送料)/ (1- 希望利益率/100- 0.139), 1) #=ROUNDDOWN((AI4+BL4)/(1-BS4/100-0.139),1)\n",
        "    希望営業利益 = 販売額 - 最安仕入価格 - 支出合計\n",
        "    Positive = round((最安仕入価格 + 送料)/ (1- 0.4- 0.139),1) # 40%\n",
        "    Middle = round((最安仕入価格 + 送料)/ (1- 0.25- 0.139),1) # 25%\n",
        "    Negative = round((最安仕入価格 + 送料)/ (1- 0.08- 0.139),1) # 8\n",
        "\n",
        "    # 横一列のDF　これをto_sql 直前に追加、最終行までフィル\n",
        "    funcs_df = pd.DataFrame({'kg': kg, 'integrated': integrated, '相場価格': 相場価格,\n",
        "                             '最高販売価格': 最高販売価格, '最高売値': 最高売値, '最安仕入価格': 最安仕入価格,\n",
        "                             '粗利': 粗利, '希望利益率': 希望利益率, '仕入送料': 仕入送料, '送料設定': 送料設定,\n",
        "                             '送料': 送料, '出品料': 出品料, '落札料': 落札料, 'Paypal': Paypal,\n",
        "                             '支出合計': 支出合計, '仕入れ値上限': 仕入れ値上限, '営業利益': 営業利益,\n",
        "                            '利益率': 利益率, '販売額': 販売額, '希望営業利益': 希望営業利益,\n",
        "                            'Positive': Positive, 'Middle': Middle, 'Negative': Negative})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "U_vP_kqNs8aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    concat_fin = pd.concat([concat3, funcs_df], axis=1).fillna(method='pad')\n",
        "    concat_fin.to_sql('atklist2', con=engine, if_exists='append',  # or replace\n",
        "                   index=False)\n",
        "\n",
        "# el_main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "Cqbn4TA8s8aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "Collapsed": "false",
        "id": "MAtgBhPws8ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}